{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ2zex-Zt0at",
        "outputId": "84a50cb7-ff9b-498f-b4a9-9082428abf3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0lQaXweNuEos"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_19_20 = pd.read_csv('/content/drive/MyDrive/DS340W/pl_19-20.csv')\n",
        "pl_20_21 = pd.read_csv('/content/drive/MyDrive/DS340W/pl_20-21.csv')\n",
        "pl_21_22 = pd.read_csv('/content/drive/MyDrive/DS340W/pl_21-22.csv')\n",
        "pl_22_23 = pd.read_csv('/content/drive/MyDrive/DS340W/pl_22-23.csv')\n",
        "pl_23_24 = pd.read_csv('/content/drive/MyDrive/DS340W/pl_23-24.csv')\n",
        "player_injuries = pd.read_csv('/content/drive/MyDrive/DS340W/player_injuries_impact.csv')"
      ],
      "metadata": {
        "id": "Gr1X4FxeuGSP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pl_19_20['Name'] = pl_19_20['Name'].str.strip()\n",
        "pl_20_21['Name'] = pl_20_21['Name'].str.strip()\n",
        "pl_21_22['Name'] = pl_21_22['Name'].str.strip()\n",
        "pl_22_23['Name'] = pl_22_23['Name'].str.strip()\n",
        "pl_23_24['Name'] = pl_23_24['Name'].str.strip()\n",
        "player_injuries['Name'] = player_injuries['Name'].str.strip()\n",
        "\n",
        "merged_seasons = []\n",
        "\n",
        "seasons_data = {\n",
        "    '2019/20': pl_19_20,\n",
        "    '2020/21': pl_20_21,\n",
        "    '2021/22': pl_21_22,\n",
        "    '2022/23': pl_22_23,\n",
        "    '2023/24': pl_23_24\n",
        "}\n",
        "\n",
        "for season, pl_data in seasons_data.items():\n",
        "    season_injuries = player_injuries[player_injuries['Season'] == season]\n",
        "    merged_season = pd.merge(pl_data, season_injuries, on='Name', how='left')\n",
        "    merged_season['Season'] = season\n",
        "    merged_seasons.append(merged_season)\n",
        "\n",
        "all_seasons_merged = pd.concat(merged_seasons, ignore_index=True)\n",
        "\n",
        "print(f\"Non-null injury records: {all_seasons_merged['Injury'].notna().sum()}\")\n",
        "print(f\"Null injury records: {all_seasons_merged['Injury'].isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGut4rF72kuE",
        "outputId": "c89cd116-0f98-4bf1-c1ae-aeb142ad10b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Non-null injury records: 525\n",
            "Null injury records: 4601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_seasons_merged = all_seasons_merged.drop(columns=['Unnamed: 0', 'Team Name', 'Position_y', 'Goals conceded', 'Goals Conceded',\n",
        "                                                      'Big Chances Created', 'Big chances missed', 'Freekicks scored', 'Own goals',\n",
        "                                                      'Errors leading to goal', 'Offsides', 'Penalties Saved'])\n",
        "all_seasons_merged = all_seasons_merged.rename(columns={\"Position_x\":\"Position\"})\n",
        "all_seasons_merged = all_seasons_merged[all_seasons_merged['Injury'].notna()]"
      ],
      "metadata": {
        "id": "7UvHdGxU1DfS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_seasons_merged = all_seasons_merged.fillna(0)\n",
        "all_seasons_merged.to_csv('/content/drive/MyDrive/DS340W/all_seasons_merged.csv', index = False)\n",
        "\n",
        "display(all_seasons_merged.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "sKnJRzZs1WEf",
        "outputId": "816d12a6-2704-40d2-ed86-5d189f414020"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              Name    Position  Appearances  Clean sheets  Tackles  \\\n",
              "24       Dele Alli  Midfielder           25           0.0     34.0   \n",
              "25       Dele Alli  Midfielder           25           0.0     34.0   \n",
              "26  Miguel Almirón  Midfielder           36           0.0     60.0   \n",
              "35     André Gomes  Midfielder           19           0.0     22.0   \n",
              "36     André Gomes  Midfielder           19           0.0     22.0   \n",
              "\n",
              "   Tackle success %  Last man tackles  Blocked shots  Interceptions  \\\n",
              "24              47%               0.0            7.0           17.0   \n",
              "25              47%               0.0            7.0           17.0   \n",
              "26              65%               0.0           19.0           31.0   \n",
              "35              68%               0.0            0.0            7.0   \n",
              "36              68%               0.0            0.0            7.0   \n",
              "\n",
              "    Clearances  ...  High Claims  Catches  Sweeper clearances  Throw outs  \\\n",
              "24        14.0  ...          0.0      0.0                 0.0         0.0   \n",
              "25        14.0  ...          0.0      0.0                 0.0         0.0   \n",
              "26        16.0  ...          0.0      0.0                 0.0         0.0   \n",
              "35         6.0  ...          0.0      0.0                 0.0         0.0   \n",
              "36         6.0  ...          0.0      0.0                 0.0         0.0   \n",
              "\n",
              "    Goal Kicks   Age   Season            Injury  Date of Injury Date of return  \n",
              "24         0.0  23.0  2019/20  Hamstring injury      Aug 4,2019    Aug 31,2019  \n",
              "25         0.0  24.0  2019/20     Muscle injury      Jul 3,2020    Jul 25,2020  \n",
              "26         0.0  26.0  2019/20  Hamstring injury        9-Dec-19      20-Dec-19  \n",
              "35         0.0  26.0  2019/20      bruised ribs        2-Sep-19       4-Oct-19  \n",
              "36         0.0  26.0  2019/20      ankle injury        4-Nov-19      21-Feb-20  \n",
              "\n",
              "[5 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82c61616-9c81-4633-acfd-ad4d6ba1d3f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Position</th>\n",
              "      <th>Appearances</th>\n",
              "      <th>Clean sheets</th>\n",
              "      <th>Tackles</th>\n",
              "      <th>Tackle success %</th>\n",
              "      <th>Last man tackles</th>\n",
              "      <th>Blocked shots</th>\n",
              "      <th>Interceptions</th>\n",
              "      <th>Clearances</th>\n",
              "      <th>...</th>\n",
              "      <th>High Claims</th>\n",
              "      <th>Catches</th>\n",
              "      <th>Sweeper clearances</th>\n",
              "      <th>Throw outs</th>\n",
              "      <th>Goal Kicks</th>\n",
              "      <th>Age</th>\n",
              "      <th>Season</th>\n",
              "      <th>Injury</th>\n",
              "      <th>Date of Injury</th>\n",
              "      <th>Date of return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Dele Alli</td>\n",
              "      <td>Midfielder</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>47%</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2019/20</td>\n",
              "      <td>Hamstring injury</td>\n",
              "      <td>Aug 4,2019</td>\n",
              "      <td>Aug 31,2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Dele Alli</td>\n",
              "      <td>Midfielder</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>47%</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2019/20</td>\n",
              "      <td>Muscle injury</td>\n",
              "      <td>Jul 3,2020</td>\n",
              "      <td>Jul 25,2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Miguel Almirón</td>\n",
              "      <td>Midfielder</td>\n",
              "      <td>36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>65%</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2019/20</td>\n",
              "      <td>Hamstring injury</td>\n",
              "      <td>9-Dec-19</td>\n",
              "      <td>20-Dec-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>André Gomes</td>\n",
              "      <td>Midfielder</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>68%</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2019/20</td>\n",
              "      <td>bruised ribs</td>\n",
              "      <td>2-Sep-19</td>\n",
              "      <td>4-Oct-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>André Gomes</td>\n",
              "      <td>Midfielder</td>\n",
              "      <td>19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>68%</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2019/20</td>\n",
              "      <td>ankle injury</td>\n",
              "      <td>4-Nov-19</td>\n",
              "      <td>21-Feb-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 52 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82c61616-9c81-4633-acfd-ad4d6ba1d3f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82c61616-9c81-4633-acfd-ad4d6ba1d3f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82c61616-9c81-4633-acfd-ad4d6ba1d3f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4af4be70-e815-4ea9-a1f1-c12f6de9cd0d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4af4be70-e815-4ea9-a1f1-c12f6de9cd0d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4af4be70-e815-4ea9-a1f1-c12f6de9cd0d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, temp_df = train_test_split(all_seasons_merged, test_size = 0.3, random_state = 42)\n",
        "test_df, val_df = train_test_split(temp_df, test_size = 1/3, random_state = 42)\n",
        "\n",
        "print(\"Training set shape:\", train_df.shape)\n",
        "print(\"Testing set shape:\", test_df.shape)\n",
        "print(\"Validation set shape:\", val_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyW30OT_wvpq",
        "outputId": "d23688f7-528e-4f17-e03d-18a99fb9cb13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (367, 52)\n",
            "Testing set shape: (105, 52)\n",
            "Validation set shape: (53, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/DS340W/asm_train.csv', index = False)\n",
        "test_df.to_csv('/content/drive/MyDrive/DS340W/asm_test.csv', index = False)\n",
        "val_df.to_csv('/content/drive/MyDrive/DS340W/asm_val.csv', index = False)"
      ],
      "metadata": {
        "id": "SWsK8ptew3GC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                           confusion_matrix, classification_report, mean_squared_error,\n",
        "                           r2_score, mean_absolute_error)\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class InjuryAnalysisML:\n",
        "    def __init__(self, train_df, test_df, validation_df):\n",
        "        self.train_df = pd.DataFrame(train_df.copy())\n",
        "        self.test_df = pd.DataFrame(test_df.copy())\n",
        "        self.validation_df = pd.DataFrame(validation_df.copy())\n",
        "\n",
        "        for df in [self.train_df, self.test_df, self.validation_df]:\n",
        "            for col in df.columns:\n",
        "                if hasattr(df[col], 'cat'):\n",
        "                    df[col] = df[col].astype(str)\n",
        "\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.models = {}\n",
        "        self.results = {}\n",
        "\n",
        "    def preprocess_data(self):\n",
        "        all_data = all_seasons_merged.reset_index(drop=True)\n",
        "        for col in all_data.columns:\n",
        "            if all_data[col].dtype == 'object' or str(all_data[col].dtype) == 'category':\n",
        "                all_data[col] = all_data[col].astype(str).replace('nan', '')\n",
        "        percentage_cols = [col for col in all_data.columns if '%' in str(col)]\n",
        "        for col in percentage_cols:\n",
        "            all_data[col] = pd.to_numeric(all_data[col].astype(str).str.replace('%', ''), errors='coerce')\n",
        "\n",
        "        numeric_cols = []\n",
        "        for col in ['Appearances', 'Clean sheets', 'Tackles', 'Last man tackles',\n",
        "                   'Blocked shots', 'Interceptions', 'Clearances', 'Age']:\n",
        "            if col in all_data.columns:\n",
        "                numeric_cols.append(col)\n",
        "                all_data[col] = pd.to_numeric(all_data[col], errors='coerce')\n",
        "\n",
        "        print(f\"Numeric columns identified: {numeric_cols}\")\n",
        "\n",
        "        try:\n",
        "            if 'Date of Injury' in all_data.columns and 'Date of return' in all_data.columns:\n",
        "                date_formats = ['%b %d,%Y', '%d-%b-%y', '%Y-%m-%d', '%m/%d/%Y']\n",
        "\n",
        "                for date_col in ['Date of Injury', 'Date of return']:\n",
        "                    all_data[date_col] = pd.to_datetime(all_data[date_col], errors='coerce')\n",
        "                    if all_data[date_col].isna().all():\n",
        "                        for fmt in date_formats:\n",
        "                            try:\n",
        "                                all_data[date_col] = pd.to_datetime(all_data[date_col], format=fmt, errors='coerce')\n",
        "                                if not all_data[date_col].isna().all():\n",
        "                                    break\n",
        "                            except:\n",
        "                                continue\n",
        "\n",
        "                duration = (all_data['Date of return'] - all_data['Date of Injury']).dt.days\n",
        "                all_data['injury_duration_days'] = duration.fillna(14).clip(lower=1, upper=365)\n",
        "            else:\n",
        "                print(\"Date columns not found, using default duration\")\n",
        "                all_data['injury_duration_days'] = 14\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Date parsing failed: {e}. Using default duration of 14 days.\")\n",
        "            all_data['injury_duration_days'] = 14\n",
        "\n",
        "        def get_severity(days):\n",
        "            if pd.isna(days) or days <= 7:\n",
        "                return 'Minor'\n",
        "            elif days <= 21:\n",
        "                return 'Moderate'\n",
        "            elif days <= 60:\n",
        "                return 'Severe'\n",
        "            else:\n",
        "                return 'Critical'\n",
        "\n",
        "        all_data['injury_severity'] = all_data['injury_duration_days'].apply(get_severity)\n",
        "\n",
        "        if 'Injury' in all_data.columns:\n",
        "            all_data['injury_type_category'] = all_data['Injury'].astype(str).str.extract(r'(\\w+)')[0].str.lower().fillna('unknown')\n",
        "        else:\n",
        "            all_data['injury_type_category'] = 'unknown'\n",
        "\n",
        "        if 'Appearances' in all_data.columns:\n",
        "            appearances = np.maximum(all_data['Appearances'].fillna(1), 1)\n",
        "        else:\n",
        "            appearances = 1\n",
        "\n",
        "        for metric_col, rate_col in [('Tackles', 'tackle_rate'),\n",
        "                                    ('Interceptions', 'interception_rate'),\n",
        "                                    ('Clearances', 'clearance_rate')]:\n",
        "            if metric_col in all_data.columns:\n",
        "                all_data[rate_col] = all_data[metric_col].fillna(0) / appearances\n",
        "            else:\n",
        "                all_data[rate_col] = 0\n",
        "\n",
        "        if 'Age' in all_data.columns:\n",
        "            age = all_data['Age'].fillna(25)\n",
        "            all_data['age_group'] = pd.cut(age, bins=[0, 23, 28, 33, 40],\n",
        "                                          labels=['Young', 'Prime', 'Experienced', 'Veteran'],\n",
        "                                          include_lowest=True).astype(str)\n",
        "        else:\n",
        "            all_data['age_group'] = 'Prime'\n",
        "\n",
        "        potential_feature_columns = [\n",
        "            'Appearances', 'Clean sheets', 'Tackles', 'Tackle success %', 'Last man tackles',\n",
        "            'Blocked shots', 'Interceptions', 'Clearances', 'Age',\n",
        "            'tackle_rate', 'interception_rate', 'clearance_rate'\n",
        "        ]\n",
        "\n",
        "        feature_columns = []\n",
        "        for col in potential_feature_columns:\n",
        "            if col in all_data.columns:\n",
        "                feature_columns.append(col)\n",
        "                if all_data[col].dtype in ['int64', 'float64']:\n",
        "                    all_data[col] = all_data[col].fillna(all_data[col].median())\n",
        "            else:\n",
        "                print(f\"Warning: Column '{col}' not found in data. Skipping.\")\n",
        "\n",
        "        categorical_columns = ['Position', 'injury_type_category', 'age_group']\n",
        "\n",
        "        for col in categorical_columns:\n",
        "            if col in all_data.columns:\n",
        "                all_data[col] = all_data[col].astype(str).replace('nan', 'Unknown').fillna('Unknown')\n",
        "\n",
        "                le = LabelEncoder()\n",
        "                all_data[col + '_encoded'] = le.fit_transform(all_data[col])\n",
        "                self.label_encoders[col] = le\n",
        "                feature_columns.append(col + '_encoded')\n",
        "\n",
        "        for col in feature_columns:\n",
        "            if col in all_data.columns:\n",
        "                if all_data[col].dtype in ['int64', 'float64']:\n",
        "                    all_data[col] = all_data[col].fillna(0)\n",
        "\n",
        "        train_size = len(self.train_df)\n",
        "        test_size = len(self.test_df)\n",
        "\n",
        "        self.train_processed = all_data.iloc[:train_size].copy()\n",
        "        self.test_processed = all_data.iloc[train_size:train_size + test_size].copy()\n",
        "        self.validation_processed = all_data.iloc[train_size + test_size:].copy()\n",
        "\n",
        "        self.feature_columns = feature_columns\n",
        "\n",
        "\n",
        "    def prepare_features_targets(self):\n",
        "        #Features\n",
        "        X_train = self.train_processed[self.feature_columns].copy()\n",
        "        X_test = self.test_processed[self.feature_columns].copy()\n",
        "        X_validation = self.validation_processed[self.feature_columns].copy()\n",
        "\n",
        "        #Fill any remaining NaN values with 0\n",
        "        X_train = X_train.fillna(0)\n",
        "        X_test = X_test.fillna(0)\n",
        "        X_validation = X_validation.fillna(0)\n",
        "\n",
        "        #Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "        X_validation_scaled = self.scaler.transform(X_validation)\n",
        "\n",
        "        #Injury duration\n",
        "        y_duration_train = self.train_processed['injury_duration_days'].fillna(14).astype(float)\n",
        "        y_duration_test = self.test_processed['injury_duration_days'].fillna(14).astype(float)\n",
        "        y_duration_validation = self.validation_processed['injury_duration_days'].fillna(14).astype(float)\n",
        "\n",
        "        #Injury severity\n",
        "        y_severity_train = self.train_processed['injury_severity'].astype(str).replace('nan', 'Minor')\n",
        "        y_severity_test = self.test_processed['injury_severity'].astype(str).replace('nan', 'Minor')\n",
        "        y_severity_validation = self.validation_processed['injury_severity'].astype(str).replace('nan', 'Minor')\n",
        "\n",
        "        #Injury type\n",
        "        y_type_train = self.train_processed['injury_type_category'].astype(str).replace('nan', 'unknown')\n",
        "        y_type_test = self.test_processed['injury_type_category'].astype(str).replace('nan', 'unknown')\n",
        "        y_type_validation = self.validation_processed['injury_type_category'].astype(str).replace('nan', 'unknown')\n",
        "\n",
        "        return {\n",
        "            'X_train': X_train, 'X_test': X_test, 'X_validation': X_validation,\n",
        "            'X_train_scaled': X_train_scaled, 'X_test_scaled': X_test_scaled, 'X_validation_scaled': X_validation_scaled,\n",
        "            'y_duration': {'train': y_duration_train, 'test': y_duration_test, 'validation': y_duration_validation},\n",
        "            'y_severity': {'train': y_severity_train, 'test': y_severity_test, 'validation': y_severity_validation},\n",
        "            'y_type': {'train': y_type_train, 'test': y_type_test, 'validation': y_type_validation}\n",
        "        }\n",
        "\n",
        "    def train_classification_models(self, data_dict, target_type='severity'):\n",
        "        \"\"\"Train classification models\"\"\"\n",
        "\n",
        "        X_train = data_dict['X_train_scaled']\n",
        "        X_test = data_dict['X_test_scaled']\n",
        "        y_train = data_dict[f'y_{target_type}']['train']\n",
        "        y_test = data_dict[f'y_{target_type}']['test']\n",
        "\n",
        "        classification_models = {\n",
        "            'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "            'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "            'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "            'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
        "            'Naive Bayes': GaussianNB(),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for name, model in classification_models.items():\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "                cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy')\n",
        "                accuracy = accuracy_score(y_test, y_pred)\n",
        "                precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "                recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "                f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "                results[name] = {\n",
        "                    'model': model,\n",
        "                    'accuracy': accuracy,\n",
        "                    'precision': precision,\n",
        "                    'recall': recall,\n",
        "                    'f1_score': f1,\n",
        "                    'cv_mean': cv_scores.mean(),\n",
        "                    'cv_std': cv_scores.std(),\n",
        "                    'predictions': y_pred\n",
        "                }\n",
        "\n",
        "                print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "                print(f\"  CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    def train_regression_models(self, data_dict):\n",
        "        \"\"\"Train regression models for injury duration prediction\"\"\"\n",
        "\n",
        "        X_train = data_dict['X_train_scaled']\n",
        "        X_test = data_dict['X_test_scaled']\n",
        "        y_train = data_dict['y_duration']['train']\n",
        "        y_test = data_dict['y_duration']['test']\n",
        "\n",
        "        regression_models = {\n",
        "            'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "            'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
        "            'Linear Regression': LinearRegression()\n",
        "        }\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        for name, model in regression_models.items():\n",
        "            try:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "                cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_squared_error')\n",
        "                mse = mean_squared_error(y_test, y_pred)\n",
        "                rmse = np.sqrt(mse)\n",
        "                mae = mean_absolute_error(y_test, y_pred)\n",
        "                r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "                results[name] = {\n",
        "                    'model': model,\n",
        "                    'mse': mse,\n",
        "                    'rmse': rmse,\n",
        "                    'mae': mae,\n",
        "                    'r2_score': r2,\n",
        "                    'cv_mean': -cv_scores.mean(),\n",
        "                    'cv_std': cv_scores.std(),\n",
        "                    'predictions': y_pred\n",
        "                }\n",
        "\n",
        "                print(f\"  RMSE: {rmse:.4f}\")\n",
        "                print(f\"  R²: {r2:.4f}\")\n",
        "                print(f\"  CV RMSE: {np.sqrt(-cv_scores.mean()):.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error training {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        return results\n",
        "\n",
        "    def feature_importance_analysis(self, model_results, model_name='Random Forest'):\n",
        "        \"\"\"Analyze feature importance\"\"\"\n",
        "        print(f\"\\nFeature Importance Analysis for {model_name}...\")\n",
        "\n",
        "        if model_name in model_results:\n",
        "            model = model_results[model_name]['model']\n",
        "\n",
        "            if hasattr(model, 'feature_importances_'):\n",
        "                importance_df = pd.DataFrame({\n",
        "                    'feature': self.feature_columns,\n",
        "                    'importance': model.feature_importances_\n",
        "                }).sort_values('importance', ascending=False)\n",
        "\n",
        "                print(\"\\nTop 10 Most Important Features:\")\n",
        "                print(importance_df.head(10))\n",
        "\n",
        "                return importance_df\n",
        "\n",
        "        return None\n",
        "\n",
        "    def print_model_comparison(self, results_dict, task_type='classification'):\n",
        "        \"\"\"Print comparison of model performances\"\"\"\n",
        "        if not results_dict:\n",
        "            print(f\"No results available for {task_type}\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n{task_type.upper()} MODEL COMPARISON:\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        if task_type == 'classification':\n",
        "            print(f\"{'Model':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'CV Score':<10}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "            for name, results in results_dict.items():\n",
        "                print(f\"{name:<20} {results['accuracy']:<10.4f} {results['precision']:<10.4f} \"\n",
        "                      f\"{results['recall']:<10.4f} {results['f1_score']:<10.4f} {results['cv_mean']:<10.4f}\")\n",
        "\n",
        "        elif task_type == 'regression':\n",
        "            print(f\"{'Model':<20} {'RMSE':<10} {'MAE':<10} {'R²':<10} {'CV RMSE':<10}\")\n",
        "            print(\"-\" * 70)\n",
        "\n",
        "            for name, results in results_dict.items():\n",
        "                cv_rmse = np.sqrt(results['cv_mean'])\n",
        "                print(f\"{name:<20} {results['rmse']:<10.4f} {results['mae']:<10.4f} \"\n",
        "                      f\"{results['r2_score']:<10.4f} {cv_rmse:<10.4f}\")\n",
        "\n",
        "    def run_complete_analysis(self):\n",
        "        \"\"\"Run the complete ML analysis pipeline\"\"\"\n",
        "        print(\"Starting Premier League Injury Analysis\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        try:\n",
        "            self.preprocess_data()\n",
        "\n",
        "            data_dict = self.prepare_features_targets()\n",
        "\n",
        "            severity_results = self.train_classification_models(data_dict, target_type='severity')\n",
        "\n",
        "            type_results = self.train_classification_models(data_dict, target_type='type')\n",
        "\n",
        "            duration_results = self.train_regression_models(data_dict)\n",
        "\n",
        "            self.print_model_comparison(severity_results, 'classification')\n",
        "            self.print_model_comparison(duration_results, 'regression')\n",
        "\n",
        "            if severity_results:\n",
        "                severity_importance = self.feature_importance_analysis(severity_results, 'Random Forest')\n",
        "            else:\n",
        "                severity_importance = None\n",
        "\n",
        "            self.results = {\n",
        "                'severity_classification': severity_results,\n",
        "                'type_classification': type_results,\n",
        "                'duration_regression': duration_results,\n",
        "                'feature_importance': severity_importance\n",
        "            }\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "            if severity_results:\n",
        "                best_severity = max(severity_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "                print(f\"\\nBest Severity Classification Model: {best_severity[0]} (Accuracy: {best_severity[1]['accuracy']:.4f})\")\n",
        "\n",
        "            if duration_results:\n",
        "                best_duration = min(duration_results.items(), key=lambda x: x[1]['rmse'])\n",
        "                print(f\"Best Duration Regression Model: {best_duration[0]} (RMSE: {best_duration[1]['rmse']:.4f})\")\n",
        "\n",
        "            return self.results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in analysis: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None"
      ],
      "metadata": {
        "id": "Ns_OjKpGxoKF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = InjuryAnalysisML(train_df, test_df, val_df)\n",
        "results = analyzer.run_complete_analysis()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRmDc8uNE8BC",
        "outputId": "1dce1157-c650-4208-da0c-1480ffab8b6b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Premier League Injury Analysis\n",
            "==================================================\n",
            "Numeric columns identified: ['Appearances', 'Clean sheets', 'Tackles', 'Last man tackles', 'Blocked shots', 'Interceptions', 'Clearances', 'Age']\n",
            "  Accuracy: 0.3619\n",
            "  CV Score: 0.3677 (+/- 0.0552)\n",
            "  Accuracy: 0.3429\n",
            "  CV Score: 0.3023 (+/- 0.0909)\n",
            "  Accuracy: 0.3429\n",
            "  CV Score: 0.3678 (+/- 0.0699)\n",
            "  Accuracy: 0.3238\n",
            "  CV Score: 0.3324 (+/- 0.0201)\n",
            "  Accuracy: 0.3429\n",
            "  CV Score: 0.2480 (+/- 0.0738)\n",
            "  Accuracy: 0.3429\n",
            "  CV Score: 0.3297 (+/- 0.0473)\n",
            "  Accuracy: 0.4952\n",
            "  CV Score: 0.4685 (+/- 0.1040)\n",
            "  Accuracy: 0.8000\n",
            "  CV Score: 0.8937 (+/- 0.0274)\n",
            "  Accuracy: 0.3238\n",
            "  CV Score: 0.3432 (+/- 0.0986)\n",
            "  Accuracy: 0.1524\n",
            "  CV Score: 0.1499 (+/- 0.0149)\n",
            "  Accuracy: 0.7714\n",
            "  CV Score: 0.8528 (+/- 0.0469)\n",
            "  Accuracy: 0.7524\n",
            "  CV Score: 0.8582 (+/- 0.0777)\n",
            "  RMSE: 62.7474\n",
            "  R²: 0.2099\n",
            "  CV RMSE: 53.3211\n",
            "  RMSE: 96.8483\n",
            "  R²: -0.8823\n",
            "  CV RMSE: 74.7006\n",
            "  RMSE: 65.5644\n",
            "  R²: 0.1373\n",
            "  CV RMSE: 52.7425\n",
            "\n",
            "CLASSIFICATION MODEL COMPARISON:\n",
            "--------------------------------------------------------------------------------\n",
            "Model                Accuracy   Precision  Recall     F1-Score   CV Score  \n",
            "--------------------------------------------------------------------------------\n",
            "Random Forest        0.3619     0.3790     0.3619     0.3405     0.3677    \n",
            "Decision Tree        0.3429     0.3446     0.3429     0.3229     0.3023    \n",
            "Logistic Regression  0.3429     0.3091     0.3429     0.2479     0.3678    \n",
            "K-Nearest Neighbors  0.3238     0.3684     0.3238     0.3058     0.3324    \n",
            "Naive Bayes          0.3429     0.3533     0.3429     0.3243     0.2480    \n",
            "Gradient Boosting    0.3429     0.3710     0.3429     0.3347     0.3297    \n",
            "\n",
            "REGRESSION MODEL COMPARISON:\n",
            "--------------------------------------------------------------------------------\n",
            "Model                RMSE       MAE        R²         CV RMSE   \n",
            "----------------------------------------------------------------------\n",
            "Random Forest        62.7474    36.9578    0.2099     53.3211   \n",
            "Decision Tree        96.8483    57.2403    -0.8823    74.7006   \n",
            "Linear Regression    65.5644    38.3202    0.1373     52.7425   \n",
            "\n",
            "Feature Importance Analysis for Random Forest...\n",
            "\n",
            "Top 10 Most Important Features:\n",
            "                         feature  importance\n",
            "13  injury_type_category_encoded    0.200508\n",
            "0                    Appearances    0.088400\n",
            "11                clearance_rate    0.087476\n",
            "9                    tackle_rate    0.078856\n",
            "8                            Age    0.076606\n",
            "2                        Tackles    0.073603\n",
            "7                     Clearances    0.071174\n",
            "10             interception_rate    0.069722\n",
            "6                  Interceptions    0.060521\n",
            "3               Tackle success %    0.057619\n",
            "\n",
            "==================================================\n",
            "\n",
            "Best Severity Classification Model: Random Forest (Accuracy: 0.3619)\n",
            "Best Duration Regression Model: Random Forest (RMSE: 62.7474)\n"
          ]
        }
      ]
    }
  ]
}